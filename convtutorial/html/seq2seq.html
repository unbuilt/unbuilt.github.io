
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>序列到序列生成 &#8212; 对话系统实践：快速上手  文档</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/translations.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="索引" href="genindex.html" />
    <link rel="search" title="搜索" href="search.html" />
    <link rel="next" title="基于预训练的对话生成" href="gpt.html" />
    <link rel="prev" title="基于生成的方法" href="generative.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="id1">
<h1>序列到序列生成<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<p><cite>Sequence to Sequence Learning with Neural Networks</cite> <a class="reference internal" href="reference.html#seq2seq" id="id2"><span>[Seq2Seq]</span></a> 这篇文章描述了序列到序列模型，它读入一个输入句子，先通过循环神经网络编码成一个隐式的向量，再根据这个隐式的向量使用循环神经网络语言模型输出一个句子。这个模型在机器翻译问题上取得了很好的效果，也被用在于诸如图片描述生成、问答、对话生成等任务上。</p>
<section id="id3">
<h2>循环神经网络<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<p>循环神经网络是神经元可以接受自身信息从而形成环路的网络结构，能够处理像自然语言中的句子等任意长度的序列数据。</p>
<p><code class="docutils literal notranslate"><span class="pre">神经网络与深度学习</span></code> <a class="reference internal" href="reference.html#nndl" id="id4"><span>[NNDL]</span></a> 这本书讲解了神经网络与深度学习技术的基本原理，其中包括了循环神经网络等基础的神经网络模型。</p>
<p><a class="reference external" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>
和 <a class="reference external" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a>
这两篇文章是学习循环神经网络的很好的参考。</p>
</section>
<section id="lstm">
<h2>基于LSTM的序列到序列对话生成<a class="headerlink" href="#lstm" title="永久链接至标题">¶</a></h2>
<p>根据序列到序列模型，实现对话生成需要如下步骤：</p>
<ol class="arabic simple">
<li><p>数据预处理：把对话数据处理成QA对。</p></li>
<li><p>建立词典：后续模型学习需要使用数字代替词，这一步根据QA对建立词典，词典为每个词生成一个唯一的数字，并提供词到数字的相互转换功能。</p></li>
<li><p>实现模型：使用Pytorch实现编码器模型及解码器模型。</p></li>
<li><p>训练模型：使用QA训练模型。</p></li>
<li><p>生成对话：使用训练好的模型生成对话回复。</p></li>
</ol>
<p>这里来实现一个基于 <code class="docutils literal notranslate"><span class="pre">LSTM</span></code> 的序列到序列对话生成模型。本节大量参考了 <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> 的 <code class="docutils literal notranslate"><span class="pre">Chatbot</span> <span class="pre">Tutorial</span></code> <a class="reference internal" href="reference.html#chatbot" id="id5"><span>[Chatbot]</span></a> 。</p>
<section id="id6">
<h3>数据预处理<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h3>
<p>这里依旧使用 <code class="docutils literal notranslate"><span class="pre">CDial-GPT</span></code> 开放的数据集作为生成模型的训练数据。首先处理原始数据为问答对。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">process_corpus</span><span class="p">(</span><span class="n">datapath</span><span class="p">,</span> <span class="n">output_path</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">datapath</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
    <span class="n">convs</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">qas</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">convs</span><span class="p">):</span>
        <span class="n">qas</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">conv</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">conv</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>

    <span class="n">qas</span> <span class="o">=</span> <span class="p">[(</span><span class="n">q</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">qas</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">30</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">30</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">]</span>

    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">qas</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>处理数据后，保存到文件中备用，并重新读入。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">process_corpus</span><span class="p">(</span><span class="s1">&#39;\data\LCCC\LCCC-base-split\LCCC-base_train.json&#39;</span><span class="p">,</span> <span class="s1">&#39;\data\seq2seq\LCCC-base_train.seq2seq.json&#39;</span><span class="p">)</span>

<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;\data\seq2seq\LCCC-base_train.seq2seq.json&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">qas</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>问答对内容是这样的：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">qas</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="p">[[</span><span class="s1">&#39;道歉 ！ ！ 再有 时间 找 你 去&#39;</span><span class="p">,</span> <span class="s1">&#39;领个 搓衣板 去 吧&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;咬咬牙 这回 要 全入 了 ！&#39;</span><span class="p">,</span> <span class="s1">&#39;干完 这 一票 我 的 会员 等级 就要 升 了 ！&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;干完 这 一票 我 的 会员 等级 就要 升 了 ！&#39;</span><span class="p">,</span> <span class="s1">&#39;升 了 继续&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;代表 了 哪里 的 普通人 ？&#39;</span><span class="p">,</span> <span class="s1">&#39;我 瞎说 的&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;早点 好 起来 啊 。 生日快乐&#39;</span><span class="p">,</span> <span class="s1">&#39;好 得 差不多 啦&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;好 得 差不多 啦&#39;</span><span class="p">,</span> <span class="s1">&#39;那 很 好 啊&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;那么 早 ！ ！ 我 的 考试 周 还 没有 开始 呢 ！&#39;</span><span class="p">,</span> <span class="s1">&#39;是 啊 ， 今年 好 快 啊&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;是 啊 ， 今年 好 快 啊&#39;</span><span class="p">,</span> <span class="s1">&#39;不止 今年 ， 我 发现 你 每次 都 好 早&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;不止 今年 ， 我 发现 你 每次 都 好 早&#39;</span><span class="p">,</span> <span class="s1">&#39;小心 乌鸦嘴 ， 下 一次 就 最晚 了&#39;</span><span class="p">],</span>
<span class="p">[</span><span class="s1">&#39;今天 不 知道 能下 么 ， 不过 天 又 冷 了&#39;</span><span class="p">,</span> <span class="s1">&#39;希望 能 …&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<section id="id7">
<h3>词典及输入输出<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h3>
<p>首先编写一个 <code class="docutils literal notranslate"><span class="pre">Voc</span></code> 来生成词典。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Voc</span><span class="p">:</span>

    <span class="n">PAD_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;PAD&quot;</span>
    <span class="n">SOS_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;SOS&quot;</span>
    <span class="n">EOS_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;EOS&quot;</span>

    <span class="n">PAD_TOKEN_IDNEX</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">SOS_TOKEN_INDEX</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">EOS_TOKEN_INDEX</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">Voc</span><span class="o">.</span><span class="n">PAD_TOKEN_IDNEX</span><span class="p">:</span> <span class="n">Voc</span><span class="o">.</span><span class="n">PAD_TOKEN</span><span class="p">,</span>
            <span class="n">Voc</span><span class="o">.</span><span class="n">SOS_TOKEN_INDEX</span><span class="p">:</span> <span class="n">Voc</span><span class="o">.</span><span class="n">SOS_TOKEN</span><span class="p">,</span>
            <span class="n">Voc</span><span class="o">.</span><span class="n">EOS_TOKEN_INDEX</span><span class="p">:</span> <span class="n">Voc</span><span class="o">.</span><span class="n">EOS_TOKEN</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_sentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">trim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_count</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">keep_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">v</span> <span class="o">&gt;=</span> <span class="n">min_count</span><span class="p">:</span>
                <span class="n">keep_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;keep_words </span><span class="si">{}</span><span class="s1"> / </span><span class="si">{}</span><span class="s1"> = </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">keep_words</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_words</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">)</span>
        <span class="p">))</span>

        <span class="c1"># Reinitialize dictionaries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">Voc</span><span class="o">.</span><span class="n">PAD_TOKEN_IDNEX</span><span class="p">:</span> <span class="n">Voc</span><span class="o">.</span><span class="n">PAD_TOKEN</span><span class="p">,</span>
            <span class="n">Voc</span><span class="o">.</span><span class="n">SOS_TOKEN_INDEX</span><span class="p">:</span> <span class="n">Voc</span><span class="o">.</span><span class="n">SOS_TOKEN</span><span class="p">,</span>
            <span class="n">Voc</span><span class="o">.</span><span class="n">EOS_TOKEN_INDEX</span><span class="p">:</span> <span class="n">Voc</span><span class="o">.</span><span class="n">EOS_TOKEN</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">keep_words</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_word</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</pre></div>
</div>
<p>使用问答对数据，生成词典。这里只保留在问答对中出现过2次以上的词。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">voc</span> <span class="o">=</span> <span class="n">Voc</span><span class="p">(</span><span class="s1">&#39;LCCC-base&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">qas</span><span class="p">):</span>
    <span class="n">voc</span><span class="o">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
    <span class="n">voc</span><span class="o">.</span><span class="n">add_sentence</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="n">MIN_COUNT</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">voc</span><span class="o">.</span><span class="n">trim</span><span class="p">(</span><span class="n">MIN_COUNT</span><span class="p">)</span>
</pre></div>
</div>
<p>根据过滤后的词典，再次处理问答对，去掉那些含有不在词典中的词的句子。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keep_qas</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">qas</span><span class="p">):</span>
    <span class="n">keep_q</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">keep_a</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">q</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">voc</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="n">keep_q</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">break</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">a</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">voc</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="n">keep_a</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">break</span>
    <span class="k">if</span> <span class="n">keep_q</span> <span class="ow">and</span> <span class="n">keep_a</span><span class="p">:</span>
        <span class="n">keep_qas</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">q</span><span class="p">,</span> <span class="n">a</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trimmed from </span><span class="si">{}</span><span class="s2"> pairs to </span><span class="si">{}</span><span class="s2">, </span><span class="si">{:.4f}</span><span class="s2"> of total&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">qas</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_qas</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_qas</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">qas</span><span class="p">)))</span>
</pre></div>
</div>
<p>实现几个辅助函数，用于转换数据。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">words_to_indexes</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">words</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">voc</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">Voc</span><span class="o">.</span><span class="n">EOS_TOKEN_INDEX</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">zero_padding</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">fillvalue</span><span class="o">=</span><span class="n">Voc</span><span class="o">.</span><span class="n">PAD_TOKEN_IDNEX</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="o">*</span><span class="n">l</span><span class="p">,</span> <span class="n">fillvalue</span><span class="o">=</span><span class="n">fillvalue</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">binary_matrix</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">Voc</span><span class="o">.</span><span class="n">PAD_TOKEN_IDNEX</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">l</span><span class="p">:</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="n">Voc</span><span class="o">.</span><span class="n">PAD_TOKEN_IDNEX</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">]</span>
        <span class="n">m</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">m</span>

<span class="k">def</span> <span class="nf">input_var</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">voc</span><span class="p">):</span>
    <span class="n">indexes_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">words_to_indexes</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span> <span class="k">for</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="n">indexes_batch</span><span class="p">])</span>
    <span class="n">pad_list</span> <span class="o">=</span> <span class="n">zero_padding</span><span class="p">(</span><span class="n">indexes_batch</span><span class="p">)</span>
    <span class="n">pad_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">pad_list</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pad_var</span><span class="p">,</span> <span class="n">lengths</span>

<span class="k">def</span> <span class="nf">output_var</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">voc</span><span class="p">):</span>
    <span class="n">indexes_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">words_to_indexes</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
    <span class="n">max_target_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span> <span class="k">for</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="n">indexes_batch</span><span class="p">])</span>
    <span class="n">pad_list</span> <span class="o">=</span> <span class="n">zero_padding</span><span class="p">(</span><span class="n">indexes_batch</span><span class="p">)</span>

    <span class="n">mask</span> <span class="o">=</span> <span class="n">binary_matrix</span><span class="p">(</span><span class="n">pad_list</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">BoolTensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">pad_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">pad_list</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pad_var</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span>

<span class="k">def</span> <span class="nf">batch_train_data</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">pair_batch</span><span class="p">):</span>
    <span class="n">pair_batch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">input_batch</span><span class="p">,</span> <span class="n">output_batch</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">pair_batch</span><span class="p">:</span>
        <span class="n">input_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">output_batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">inp</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="n">input_var</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">voc</span><span class="p">)</span>
    <span class="n">outp</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">output_var</span><span class="p">(</span><span class="n">output_batch</span><span class="p">,</span> <span class="n">voc</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">outp</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span>
</pre></div>
</div>
</section>
<section id="id8">
<h3>模型<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<p>模型包括编码器，注意力机制，以及解码器。</p>
<section id="id9">
<h4>编码器<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">dropout</span><span class="p">),</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">embeded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span>
        <span class="n">packed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">embeded</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">packed</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">:]</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</section>
<section id="id10">
<h4>注意力<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Attn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attn</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;dot&#39;</span><span class="p">,</span> <span class="s1">&#39;general&#39;</span><span class="p">,</span> <span class="s1">&#39;concat&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span> <span class="s2">&quot;is not an appropriate attention method.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;general&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;concat&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_dot_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hidden</span> <span class="o">*</span> <span class="n">encoder_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_general_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">encoder_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hidden</span> <span class="o">*</span> <span class="n">energy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_concat_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">hidden</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">encoder_output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">encoder_output</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">*</span> <span class="n">energy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="c1"># Calculate the attention weights (energies) based on the given method</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;general&#39;</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_general_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;concat&#39;</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_concat_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;dot&#39;</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dot_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>

        <span class="c1"># Transpose max_length and batch_size dimensions</span>
        <span class="n">attn_energies</span> <span class="o">=</span> <span class="n">attn_energies</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

        <span class="c1"># Return the softmax normalized probability scores (with added dimension)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_energies</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id11">
<h4>解码器<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LuongAttnDecoderRNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn_model</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LuongAttnDecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn_model</span> <span class="o">=</span> <span class="n">attn_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">dropout</span><span class="p">),</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">Attn</span><span class="p">(</span><span class="n">attn_model</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_step</span><span class="p">,</span> <span class="n">last_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_step</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dropout</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>

        <span class="n">rnn_output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">last_hidden</span><span class="p">)</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">attn_weights</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">rnn_output</span> <span class="o">=</span> <span class="n">rnn_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">concat_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">concat_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">concat_input</span><span class="p">))</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">concat_output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</section>
</section>
<section id="id12">
<h3>训练模型<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h3>
<p>计算损失</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mask_nll_loss</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">cross_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">total</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</div>
<p>训练函数</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">input_variable</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">clip</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>

    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">input_variable</span> <span class="o">=</span> <span class="n">input_variable</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">target_variable</span> <span class="o">=</span> <span class="n">target_variable</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">print_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">totals</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_variable</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>

    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">Voc</span><span class="o">.</span><span class="n">SOS_TOKEN_INDEX</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]])</span>
    <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span><span class="p">[:</span><span class="n">decoder</span><span class="o">.</span><span class="n">n_layers</span><span class="p">]</span>

    <span class="n">use_teacher_forcing</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">teacher_forcing_ratio</span> <span class="k">else</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">use_teacher_forcing</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_target_len</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">target_variable</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">mask_loss</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">mask_nll_loss</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">mask_loss</span>
            <span class="n">totals</span> <span class="o">+=</span> <span class="n">total</span>

            <span class="n">print_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">total</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_target_len</span><span class="p">):</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">topi</span> <span class="o">=</span> <span class="n">decoder_output</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="n">topi</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]])</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">decoder_input</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">mask_loss</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">mask_nll_loss</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">mask_loss</span>
            <span class="n">totals</span> <span class="o">+=</span> <span class="n">total</span>

            <span class="n">print_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">total</span><span class="p">)</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Clip gradients: gradients are modified in place</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">clip</span><span class="p">)</span>

    <span class="c1"># Adjust model weights</span>
    <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">print_losses</span><span class="p">)</span> <span class="o">/</span> <span class="n">totals</span>
</pre></div>
</div>
<p>训练</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;s2s_model&#39;</span>
<span class="n">attn_model</span> <span class="o">=</span> <span class="s1">&#39;dot&#39;</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">encoder_n_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">decoder_n_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">encoder_n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">LuongAttnDecoderRNN</span><span class="p">(</span><span class="n">attn_model</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">,</span> <span class="n">decoder_n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Configure training/optimization</span>
<span class="n">clip</span> <span class="o">=</span> <span class="mf">50.0</span>
<span class="n">teacher_forcing_ratio</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>
<span class="n">decoder_learning_ratio</span> <span class="o">=</span> <span class="mf">5.0</span>
<span class="n">n_iteration</span> <span class="o">=</span> <span class="mi">60000</span>
<span class="n">print_every</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">save_every</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># Ensure dropout layers are in train mode</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">decoder_learning_ratio</span><span class="p">)</span>

<span class="c1"># If you have cuda, configure cuda to call</span>
<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">state</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="k">for</span> <span class="n">state</span> <span class="ow">in</span> <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">state</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">training_batches</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_train_data</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">keep_qas</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iteration</span><span class="p">)]</span>

<span class="n">save_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;save&quot;</span><span class="p">)</span>
<span class="n">corpus_name</span> <span class="o">=</span> <span class="s1">&#39;LCCC-base&#39;</span>

<span class="c1"># Initializations</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Initializing ...&#39;</span><span class="p">)</span>
<span class="n">start_iteration</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">print_loss</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Training loop</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training...&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start_iteration</span><span class="p">,</span> <span class="n">n_iteration</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
    <span class="n">training_batch</span> <span class="o">=</span> <span class="n">training_batches</span><span class="p">[</span><span class="n">iteration</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
    <span class="c1"># Extract fields from batch</span>
    <span class="n">input_variable</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span> <span class="o">=</span> <span class="n">training_batch</span>

    <span class="c1"># Run a training iteration with batch</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">input_variable</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">target_variable</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">max_target_len</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">clip</span><span class="p">)</span>
    <span class="n">print_loss</span> <span class="o">+=</span> <span class="n">loss</span>

    <span class="c1"># Print progress</span>
    <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">print_loss_avg</span> <span class="o">=</span> <span class="n">print_loss</span> <span class="o">/</span> <span class="n">print_every</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration: </span><span class="si">{}</span><span class="s2">; Percent complete: </span><span class="si">{:.1f}</span><span class="s2">%; Average loss: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="n">iteration</span> <span class="o">/</span> <span class="n">n_iteration</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">print_loss_avg</span><span class="p">))</span>
        <span class="n">print_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Save checkpoint</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iteration</span> <span class="o">%</span> <span class="n">save_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="n">directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">-</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoder_n_layers</span><span class="p">,</span> <span class="n">decoder_n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">directory</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">&#39;iteration&#39;</span><span class="p">:</span> <span class="n">iteration</span><span class="p">,</span>
            <span class="s1">&#39;en&#39;</span><span class="p">:</span> <span class="n">encoder</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;de&#39;</span><span class="p">:</span> <span class="n">decoder</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;en_opt&#39;</span><span class="p">:</span> <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;de_opt&#39;</span><span class="p">:</span> <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s1">&#39;voc_dict&#39;</span><span class="p">:</span> <span class="n">voc</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span>
            <span class="s1">&#39;embedding&#39;</span><span class="p">:</span> <span class="n">embedding</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="p">},</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">.tar&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="s1">&#39;checkpoint&#39;</span><span class="p">)))</span>
</pre></div>
</div>
<p>训练好后，模型就保存在了文件里。</p>
</section>
<section id="id13">
<h3>对话生成<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h3>
<p>我们使用前面训练好的模型，实现一个 <code class="docutils literal notranslate"><span class="pre">Seq2SeqChatAgent</span></code> 对话引擎。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">Seq2SeqChatAgent</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_filename</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">500</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_n_layers</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_n_layers</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_model</span> <span class="o">=</span> <span class="s1">&#39;dot&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="mi">30</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_filename</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;en&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;de&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_optimizer_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;en_opt&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_optimizer_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;de_opt&#39;</span><span class="p">]</span>
        <span class="n">embedding_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;embedding&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">voc</span> <span class="o">=</span> <span class="n">Voc</span><span class="p">(</span><span class="s1">&#39;LCCC-base&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">voc</span><span class="o">.</span><span class="vm">__dict__</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;voc_dict&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">embedding_sd</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">EncoderRNN</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">LuongAttnDecoderRNN</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_n_layers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder_sd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_sd</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Set dropout layers to eval mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">message</span><span class="p">):</span>
        <span class="n">input_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">message</span><span class="p">)]</span>
        <span class="c1"># words -&gt; indexes</span>
        <span class="n">indexes_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">words_to_indexes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">voc</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">)]</span>
        <span class="c1"># Create lengths tensor</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span> <span class="k">for</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="n">indexes_batch</span><span class="p">])</span>
        <span class="c1"># Transpose dimensions of batch to match models&#39; expectations</span>
        <span class="n">input_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">indexes_batch</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Use appropriate device</span>
        <span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1">#lengths = lengths.to(device)</span>

        <span class="c1"># Decode sentence with searcher</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">tokens</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_greedy_search</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">)</span>
            <span class="c1"># indexes -&gt; words</span>
            <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">voc</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
            <span class="c1"># Format response sentence</span>
            <span class="n">decoded_words</span><span class="p">[:]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">decoded_words</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;EOS&#39;</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;PAD&#39;</span><span class="p">)]</span>
            <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">decoded_words</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_greedy_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">max_length</span><span class="p">):</span>
        <span class="c1"># Forward input through encoder model</span>
        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_seq</span><span class="p">,</span> <span class="n">input_length</span><span class="p">)</span>
        <span class="c1"># Prepare encoder&#39;s final hidden layer to be first hidden input to the decoder</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">n_layers</span><span class="p">]</span>
        <span class="c1"># Initialize decoder input with SOS_token</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="o">*</span> <span class="n">Voc</span><span class="o">.</span><span class="n">SOS_TOKEN_INDEX</span>

        <span class="c1"># Initialize tensors to append decoded words to</span>
        <span class="n">all_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="n">all_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># Iteratively decode one word token at a time</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>
            <span class="c1"># Forward pass through decoder</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="c1"># Obtain most likely word token and its softmax score</span>
            <span class="n">decoder_scores</span><span class="p">,</span> <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Record token and score</span>
            <span class="n">all_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">all_tokens</span><span class="p">,</span> <span class="n">decoder_input</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">all_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">all_scores</span><span class="p">,</span> <span class="n">decoder_scores</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># Prepare current token to be next decoder input (add a dimension)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Return collections of word tokens and scores</span>
        <span class="k">return</span> <span class="n">all_tokens</span><span class="p">,</span> <span class="n">all_scores</span>
</pre></div>
</div>
<p>我们使用基于生成模型的对话引擎进行交互。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ConversationSystem</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

<span class="n">patterns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;你好[吗啊呀]?&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;*&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;你好&#39;</span><span class="p">,</span> <span class="s1">&#39;嗨&#39;</span><span class="p">]}),</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;你是男是女&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;*&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;你觉得呢&#39;</span><span class="p">,</span> <span class="s1">&#39;你呢&#39;</span><span class="p">]}),</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;你是谁&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;*&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;我是一个AI&#39;</span><span class="p">,</span> <span class="s1">&#39;我是个机器人&#39;</span><span class="p">]}),</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;你(多大|几岁)[吗啊呀]?&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;*&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;我还年轻&#39;</span><span class="p">,</span> <span class="s1">&#39;这是个秘密&#39;</span><span class="p">]}),</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;你在(哪里|哪儿|什么地方)&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;*&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;我在云端，你在哪儿&#39;</span><span class="p">,</span> <span class="s1">&#39;我在你的身边，你在哪里呢&#39;</span><span class="p">]}),</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;我是(?P&lt;Gender&gt;[男女])(的|生|人)&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;男&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;帅哥好&#39;</span><span class="p">],</span> <span class="s1">&#39;女&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;美女好&#39;</span><span class="p">]}),</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;我也?在(?P&lt;Place&gt;.+)&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;北京&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;北京现在很冷吧&#39;</span><span class="p">],</span> <span class="s1">&#39;*&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;你在</span><span class="si">{Place}</span><span class="s1">？&#39;</span><span class="p">]})</span>
<span class="p">]</span>

<span class="n">fallback_patterns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="sa">r</span><span class="s1">&#39;.*&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;*&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;你说什么&#39;</span><span class="p">,</span> <span class="s1">&#39;不好意思，没明白你的话&#39;</span><span class="p">]})</span>
<span class="p">]</span>

<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">checkpoint_iter</span> <span class="o">=</span> <span class="mi">60000</span>
    <span class="n">checkpoint_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">,</span>
        <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">-</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoder_n_layers</span><span class="p">,</span> <span class="n">decoder_n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
        <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">_checkpoint.tar&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">checkpoint_iter</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">chat_engines</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">TemplateChatAgent</span><span class="p">(</span><span class="n">ConversationSystem</span><span class="o">.</span><span class="n">patterns</span><span class="p">),</span>
        <span class="n">Seq2SeqChatAgent</span><span class="p">(</span><span class="n">checkpoint_filename</span><span class="p">),</span>
        <span class="n">TemplateChatAgent</span><span class="p">(</span><span class="n">ConversationSystem</span><span class="o">.</span><span class="n">fallback_patterns</span><span class="p">),</span>
    <span class="p">]</span>

<span class="k">def</span> <span class="nf">reply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uid</span><span class="p">,</span> <span class="n">message</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">chat_engine</span> <span class="bp">self</span><span class="o">.</span><span class="n">chat_engines</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">chat_engine</span><span class="o">.</span><span class="n">reply</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">result</span>

<span class="k">def</span> <span class="nf">interact_cli</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">query</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">&#39;User:&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">query</span> <span class="o">==</span> <span class="s1">&#39;Q&#39;</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;AI:&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reply</span><span class="p">(</span><span class="s1">&#39;UserA&#39;</span><span class="p">,</span> <span class="n">query</span><span class="p">))</span>

<span class="n">conv_system</span> <span class="o">=</span> <span class="n">ConversationSystem</span><span class="p">()</span>
<span class="n">conv_system</span><span class="o">.</span><span class="n">interact_cli</span><span class="p">()</span>
</pre></div>
</div>
<p>运行后可以得到下面的对话。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">User</span><span class="p">:</span><span class="n">你好</span>
<span class="n">AI</span><span class="p">:</span> <span class="n">你好</span>
<span class="n">User</span><span class="p">:</span><span class="n">昨天下了一场大雨</span>
<span class="n">AI</span><span class="p">:</span> <span class="n">下大雨了</span>
<span class="n">User</span><span class="p">:</span><span class="n">英超结束了</span>
<span class="n">AI</span><span class="p">:</span> <span class="n">结束了</span>
<span class="n">User</span><span class="p">:</span><span class="n">明天太阳会不会出来</span>
<span class="n">AI</span><span class="p">:</span> <span class="n">不会</span>
<span class="n">User</span><span class="p">:</span><span class="n">夏天来了</span>
<span class="n">AI</span><span class="p">:</span> <span class="n">夏天夏天夏天夏天夏天夏天夏天就来了</span>
</pre></div>
</div>
</section>
<section id="id14">
<h3>解码采样策略<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Seq2SeqChatAgent</span></code> 在生成句子时每一步都取概率最大的词，这种选择目标词的方式称为 <code class="docutils literal notranslate"><span class="pre">贪心搜索</span></code> 。这种选择方式只会产生一个生成结果。
如果在每一步多保留几个候选词，有可能会生成出更好的句子，或者使生成的结果具有多样性。这种选择目标词的方式称为 <code class="docutils literal notranslate"><span class="pre">Beam</span> <span class="pre">Search</span></code> 。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BeamSearchDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BeamSearchDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_length</span><span class="p">,</span> <span class="n">max_length</span><span class="p">):</span>
        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_seq</span><span class="p">,</span> <span class="n">input_length</span><span class="p">)</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span><span class="p">[:</span><span class="n">decoder</span><span class="o">.</span><span class="n">n_layers</span><span class="p">]</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="o">*</span> <span class="n">Voc</span><span class="o">.</span><span class="n">SOS_TOKEN_INDEX</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="p">[{</span>
            <span class="s1">&#39;Hidden&#39;</span><span class="p">:</span> <span class="n">decoder_hidden</span><span class="p">,</span>
            <span class="s1">&#39;Inputs&#39;</span><span class="p">:</span> <span class="n">decoder_input</span><span class="p">,</span>
            <span class="s1">&#39;Tokens&#39;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s1">&#39;Scores&#39;</span><span class="p">:</span> <span class="p">[]</span>
        <span class="p">}]</span>


        <span class="n">dones</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>
            <span class="n">next_candidates</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
                <span class="n">current_input</span> <span class="o">=</span> <span class="n">candidate</span><span class="p">[</span><span class="s1">&#39;Inputs&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">current_input</span> <span class="o">==</span> <span class="n">Voc</span><span class="o">.</span><span class="n">EOS_TOKEN_INDEX</span><span class="p">:</span>
                    <span class="n">dones</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="n">current_hidden</span> <span class="o">=</span> <span class="n">candidate</span><span class="p">[</span><span class="s1">&#39;Hidden&#39;</span><span class="p">]</span>
                <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">current_input</span><span class="p">,</span> <span class="n">current_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
                <span class="n">c_scores</span><span class="p">,</span> <span class="n">c_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">c_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                    <span class="n">new_score</span> <span class="o">=</span> <span class="n">candidate</span><span class="p">[</span><span class="s1">&#39;Scores&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">s</span><span class="p">]</span>
                    <span class="n">new_tokens</span> <span class="o">=</span> <span class="n">candidate</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>

                    <span class="n">next_candidates</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s1">&#39;Hidden&#39;</span><span class="p">:</span> <span class="n">decoder_hidden</span><span class="p">,</span>
                        <span class="s1">&#39;Inputs&#39;</span><span class="p">:</span> <span class="n">i</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                        <span class="s1">&#39;Tokens&#39;</span><span class="p">:</span> <span class="n">new_tokens</span><span class="p">,</span>
                        <span class="s1">&#39;Scores&#39;</span><span class="p">:</span> <span class="n">new_score</span>
                    <span class="p">})</span>

            <span class="n">next_candidates</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Scores&#39;</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Scores&#39;</span><span class="p">]))</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">]))</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">]))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">])</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dones</span><span class="p">):</span>
                <span class="k">break</span>
            <span class="n">candidates</span> <span class="o">=</span> <span class="n">next_candidates</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">dones</span><span class="p">)]</span>

        <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
            <span class="n">current_input</span> <span class="o">=</span> <span class="n">candidate</span><span class="p">[</span><span class="s1">&#39;Inputs&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">current_input</span> <span class="o">==</span> <span class="n">Voc</span><span class="o">.</span><span class="n">EOS_TOKEN_INDEX</span><span class="p">:</span>
                <span class="n">dones</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span>

        <span class="n">candidates</span> <span class="o">=</span> <span class="n">dones</span>
        <span class="n">candidates</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">e</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Scores&#39;</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Scores&#39;</span><span class="p">]))</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">]))</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">]))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">])</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">e</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">candidates</span><span class="p">:</span>
            <span class="n">candidate</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">candidate</span><span class="p">[</span><span class="s1">&#39;Tokens&#39;</span><span class="p">])</span>
            <span class="n">s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">candidate</span><span class="p">[</span><span class="s1">&#39;Scores&#39;</span><span class="p">])</span>

            <span class="k">return</span> <span class="n">r</span><span class="p">,</span> <span class="n">s</span>

        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Controllable</span> <span class="pre">Neural</span> <span class="pre">Text</span> <span class="pre">Generation</span></code> <a class="reference internal" href="reference.html#controllable" id="id15"><span>[Controllable]</span></a> 这篇文章介绍了各种解码策略。</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">对话系统实践：快速上手</a></h1>








<h3>导航</h3>
<p class="caption"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="script.html">基于脚本的方法</a></li>
<li class="toctree-l1"><a class="reference internal" href="retrieval.html">基于检索的方法</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="generative.html">基于生成的方法</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">序列到序列生成</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">循环神经网络</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lstm">基于LSTM的序列到序列对话生成</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gpt.html">基于预训练的对话生成</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">参考资料</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="generative.html">基于生成的方法</a><ul>
      <li>Previous: <a href="generative.html" title="上一章">基于生成的方法</a></li>
      <li>Next: <a href="gpt.html" title="下一章">基于预训练的对话生成</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">快速搜索</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="转向" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Eric.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.0.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/seq2seq.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>