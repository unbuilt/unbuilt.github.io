{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 序列到序列对话生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(datapath, output_path):\n",
    "    f = open(datapath, 'r', encoding='utf-8')\n",
    "    convs = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    qas = []\n",
    "    for conv in tqdm(convs):\n",
    "        qas.extend(zip(conv[:-1], conv[1:]))\n",
    "    \n",
    "    qas = [(q, a) for q, a in qas if len(q) < 30 and len(a) < 30 and len(q) > 4]\n",
    "\n",
    "    f = open(output_path, 'w', encoding='utf-8')\n",
    "    f.write(json.dumps(qas, ensure_ascii=False))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 6820506/6820506 [00:06<00:00, 1004194.31it/s]\n"
     ]
    }
   ],
   "source": [
    "process_corpus('C:\\Works\\data\\LCCC\\LCCC-base-split\\LCCC-base_train.json', 'C:\\Works\\data\\seq2seq\\LCCC-base_train.seq2seq.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('C:\\Works\\data\\seq2seq\\LCCC-base_train.seq2seq.json', 'r', encoding='utf-8')\n",
    "qas = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8831568"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['道歉 ！ ！ 再有 时间 找 你 去', '领个 搓衣板 去 吧'],\n",
       " ['咬咬牙 这回 要 全入 了 ！', '干完 这 一票 我 的 会员 等级 就要 升 了 ！'],\n",
       " ['干完 这 一票 我 的 会员 等级 就要 升 了 ！', '升 了 继续'],\n",
       " ['代表 了 哪里 的 普通人 ？', '我 瞎说 的'],\n",
       " ['早点 好 起来 啊 。 生日快乐', '好 得 差不多 啦'],\n",
       " ['好 得 差不多 啦', '那 很 好 啊'],\n",
       " ['那么 早 ！ ！ 我 的 考试 周 还 没有 开始 呢 ！', '是 啊 ， 今年 好 快 啊'],\n",
       " ['是 啊 ， 今年 好 快 啊', '不止 今年 ， 我 发现 你 每次 都 好 早'],\n",
       " ['不止 今年 ， 我 发现 你 每次 都 好 早', '小心 乌鸦嘴 ， 下 一次 就 最晚 了'],\n",
       " ['今天 不 知道 能下 么 ， 不过 天 又 冷 了', '希望 能 …']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qas[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voc:\n",
    "\n",
    "    PAD_TOKEN = \"PAD\"\n",
    "    SOS_TOKEN = \"SOS\"\n",
    "    EOS_TOKEN = \"EOS\"\n",
    "\n",
    "    PAD_TOKEN_IDNEX = 0\n",
    "    SOS_TOKEN_INDEX = 1\n",
    "    EOS_TOKEN_INDEX = 2\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            Voc.PAD_TOKEN_IDNEX: Voc.PAD_TOKEN,\n",
    "            Voc.SOS_TOKEN_INDEX: Voc.SOS_TOKEN,\n",
    "            Voc.EOS_TOKEN_INDEX: Voc.EOS_TOKEN\n",
    "        }\n",
    "        self.num_words = len(self.index2word)\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "        \n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            Voc.PAD_TOKEN_IDNEX: Voc.PAD_TOKEN,\n",
    "            Voc.SOS_TOKEN_INDEX: Voc.SOS_TOKEN,\n",
    "            Voc.EOS_TOKEN_INDEX: Voc.EOS_TOKEN\n",
    "        }\n",
    "        self.num_words = len(self.index2word)\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = Voc('LCCC-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 8831568/8831568 [00:58<00:00, 150409.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for q, a in tqdm(qas):\n",
    "    voc.add_sentence(q)\n",
    "    voc.add_sentence(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 337517 / 574723 = 0.5873\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 2\n",
    "voc.trim(MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 8831568/8831568 [00:34<00:00, 253735.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed from 8831568 pairs to 8605191, 0.9744 of total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "keep_qas = []\n",
    "for q, a in tqdm(qas):\n",
    "    keep_q = True\n",
    "    keep_a = True\n",
    "    for word in q.split():\n",
    "        if word not in voc.word2index:\n",
    "            keep_q = False\n",
    "            break\n",
    "    for word in a.split():\n",
    "        if word not in voc.word2index:\n",
    "            keep_a = False\n",
    "            break\n",
    "    if keep_q and keep_a:\n",
    "        keep_qas.append((q, a))\n",
    "    \n",
    "print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(qas), len(keep_qas), len(keep_qas) / len(qas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_indexes(voc, words):\n",
    "    return [voc.word2index[word] for word in words] + [Voc.EOS_TOKEN_INDEX]\n",
    "\n",
    "def zero_padding(l, fillvalue=Voc.PAD_TOKEN_IDNEX):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binary_matrix(l, value=Voc.PAD_TOKEN_IDNEX):\n",
    "    m = []\n",
    "    for seq in l:\n",
    "        mask = [0 if token == Voc.PAD_TOKEN_IDNEX else 1 for token in seq]\n",
    "        m.append(mask)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_var(l, voc):\n",
    "    indexes_batch = [words_to_indexes(voc, sentence.split()) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "\n",
    "    return pad_var, lengths\n",
    "\n",
    "def output_var(l, voc):\n",
    "    indexes_batch = [words_to_indexes(voc, sentence.split()) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    pad_list = zero_padding(indexes_batch)\n",
    "\n",
    "    mask = binary_matrix(pad_list)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    pad_var = torch.LongTensor(pad_list)\n",
    "\n",
    "    return pad_var, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train_data(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split()), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    \n",
    "    inp, lengths = input_var(input_batch, voc)\n",
    "    outp, mask, max_target_len = output_var(output_batch, voc)\n",
    "\n",
    "    return inp, lengths, outp, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keep_qas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e84696ae8a39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example for validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msmall_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msample_qas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep_qas\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmall_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_qas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_target_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-e84696ae8a39>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example for validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msmall_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msample_qas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep_qas\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmall_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mbatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_qas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_target_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keep_qas' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "sample_qas = [random.choice(keep_qas) for _ in range(small_batch_size)]\n",
    "batches = batch_train_data(voc, sample_qas)\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(sample_qas)\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embeded = self.embedding(input_seq)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embeded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "        \n",
    "    def _dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "    \n",
    "    def _general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "    \n",
    "    def _concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self._general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self._concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self._dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = torch.nn.Dropout(dropout)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout), bidirectional=False)\n",
    "        self.concat = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_nll_loss(inp, target, mask):\n",
    "    total = mask.sum()\n",
    "    cross_entropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = cross_entropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "\n",
    "    return loss, total.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=30):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    lengths = lengths.to('cpu')\n",
    "\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    totals = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    decoder_input = torch.LongTensor([[Voc.SOS_TOKEN_INDEX for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            mask_loss, total = mask_nll_loss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            totals += total\n",
    "\n",
    "            print_losses.append(mask_loss.item() * total)\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "\n",
    "            mask_loss, total = mask_nll_loss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            totals += total\n",
    "\n",
    "            print_losses.append(mask_loss.item() * total)\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 's2s_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LuongAttnDecoderRNN(\n",
       "  (embedding): Embedding(337520, 500)\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (gru): GRU(500, 500, num_layers=2, dropout=0.1)\n",
       "  (concat): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (out): Linear(in_features=500, out_features=337520, bias=True)\n",
       "  (attn): Attn()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 60000\n",
    "print_every = 1000\n",
    "save_every = 10000\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have cuda, configure cuda to call\n",
    "for state in encoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "for state in decoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batches = [batch_train_data(voc, [random.choice(keep_qas) for _ in range(batch_size)]) for _ in range(n_iteration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "corpus_name = 'LCCC-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                           | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                            | 1000/60000 [05:12<5:04:46,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000; Percent complete: 1.7%; Average loss: 6.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▏                                                                                          | 2000/60000 [10:19<4:48:58,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2000; Percent complete: 3.3%; Average loss: 5.6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▋                                                                                         | 3000/60000 [15:27<5:00:23,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3000; Percent complete: 5.0%; Average loss: 5.4941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▎                                                                                       | 4000/60000 [20:34<4:52:55,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4000; Percent complete: 6.7%; Average loss: 5.4182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▊                                                                                      | 5000/60000 [25:40<4:32:56,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5000; Percent complete: 8.3%; Average loss: 5.3557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▍                                                                                    | 6000/60000 [30:48<4:41:39,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6000; Percent complete: 10.0%; Average loss: 5.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▉                                                                                   | 7000/60000 [35:56<4:21:56,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7000; Percent complete: 11.7%; Average loss: 5.2636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████████▌                                                                                 | 8000/60000 [41:03<4:33:08,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8000; Percent complete: 13.3%; Average loss: 5.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████                                                                                | 9000/60000 [46:10<4:18:48,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9000; Percent complete: 15.0%; Average loss: 5.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████▋                                                                              | 9999/60000 [51:17<4:13:49,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10000; Percent complete: 16.7%; Average loss: 5.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████                                                                            | 11000/60000 [57:27<4:21:44,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11000; Percent complete: 18.3%; Average loss: 5.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████▏                                                                        | 12000/60000 [1:02:34<3:59:40,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12000; Percent complete: 20.0%; Average loss: 5.1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▋                                                                       | 13000/60000 [1:07:41<4:02:15,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13000; Percent complete: 21.7%; Average loss: 5.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████▏                                                                     | 14000/60000 [1:12:52<3:56:58,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14000; Percent complete: 23.3%; Average loss: 5.0858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████▊                                                                    | 15000/60000 [1:18:01<3:50:05,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15000; Percent complete: 25.0%; Average loss: 5.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████▎                                                                  | 16000/60000 [1:23:12<3:44:27,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 16000; Percent complete: 26.7%; Average loss: 5.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████▊                                                                 | 17000/60000 [1:28:22<3:43:31,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17000; Percent complete: 28.3%; Average loss: 5.0399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████▎                                                               | 18000/60000 [1:33:34<3:38:50,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18000; Percent complete: 30.0%; Average loss: 5.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████▊                                                              | 19000/60000 [1:38:44<3:38:34,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19000; Percent complete: 31.7%; Average loss: 5.0189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████▎                                                            | 19999/60000 [1:43:53<3:22:54,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 20000; Percent complete: 33.3%; Average loss: 5.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████████▊                                                           | 21000/60000 [1:50:23<3:20:58,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 21000; Percent complete: 35.0%; Average loss: 4.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████████▎                                                         | 22000/60000 [1:55:34<3:17:50,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 22000; Percent complete: 36.7%; Average loss: 4.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████▉                                                        | 23000/60000 [2:00:44<3:10:59,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 23000; Percent complete: 38.3%; Average loss: 4.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████▍                                                      | 24000/60000 [2:05:53<3:07:42,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 24000; Percent complete: 40.0%; Average loss: 4.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████▉                                                     | 25000/60000 [2:11:01<2:55:26,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 25000; Percent complete: 41.7%; Average loss: 4.9465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████▍                                                   | 26000/60000 [2:16:08<2:50:59,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26000; Percent complete: 43.3%; Average loss: 4.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████████████▉                                                  | 27000/60000 [2:21:13<2:46:54,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 27000; Percent complete: 45.0%; Average loss: 4.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████████▍                                                | 28000/60000 [2:26:19<2:45:42,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 28000; Percent complete: 46.7%; Average loss: 4.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████████▉                                               | 29000/60000 [2:31:25<2:43:35,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 29000; Percent complete: 48.3%; Average loss: 4.9176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████▍                                             | 29999/60000 [2:36:31<2:31:40,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 30000; Percent complete: 50.0%; Average loss: 4.9069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████████████                                            | 31000/60000 [2:43:06<2:24:43,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 31000; Percent complete: 51.7%; Average loss: 4.9044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████████████████▌                                          | 32000/60000 [2:48:13<2:21:27,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 32000; Percent complete: 53.3%; Average loss: 4.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████████                                         | 33000/60000 [2:53:19<2:14:12,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 33000; Percent complete: 55.0%; Average loss: 4.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████████▌                                       | 34000/60000 [2:58:24<2:08:05,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 34000; Percent complete: 56.7%; Average loss: 4.8839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████████                                      | 35000/60000 [3:03:29<2:07:08,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 35000; Percent complete: 58.3%; Average loss: 4.8769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████▌                                    | 36000/60000 [3:08:40<2:03:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 36000; Percent complete: 60.0%; Average loss: 4.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████████                                   | 37000/60000 [3:13:50<1:57:28,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 37000; Percent complete: 61.7%; Average loss: 4.8615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████████████▋                                 | 38000/60000 [3:19:00<1:54:45,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 38000; Percent complete: 63.3%; Average loss: 4.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████████████▏                               | 39000/60000 [3:24:10<1:47:23,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 39000; Percent complete: 65.0%; Average loss: 4.8494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████▋                              | 39999/60000 [3:29:20<1:43:12,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 40000; Percent complete: 66.7%; Average loss: 4.8427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████████▏                            | 41000/60000 [3:35:42<1:39:19,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 41000; Percent complete: 68.3%; Average loss: 4.8460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████████▋                           | 42000/60000 [3:40:52<1:33:49,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 42000; Percent complete: 70.0%; Average loss: 4.8329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████████▏                         | 43000/60000 [3:46:02<1:27:50,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 43000; Percent complete: 71.7%; Average loss: 4.8174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████████▋                        | 44000/60000 [3:51:13<1:22:29,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 44000; Percent complete: 73.3%; Average loss: 4.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████████▎                      | 45000/60000 [3:56:25<1:16:39,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 45000; Percent complete: 75.0%; Average loss: 4.8274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████████▊                     | 46000/60000 [4:01:36<1:12:50,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 46000; Percent complete: 76.7%; Average loss: 4.8159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████████▎                   | 47000/60000 [4:06:44<1:03:27,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 47000; Percent complete: 78.3%; Average loss: 4.8155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████▊                  | 48000/60000 [4:11:50<1:00:41,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 48000; Percent complete: 80.0%; Average loss: 4.8120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████████████▉                 | 49000/60000 [4:16:55<56:01,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 49000; Percent complete: 81.7%; Average loss: 4.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████████████████████████▍               | 49999/60000 [4:22:00<50:48,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50000; Percent complete: 83.3%; Average loss: 4.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████████████████████              | 51000/60000 [4:28:16<46:31,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 51000; Percent complete: 85.0%; Average loss: 4.8002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████████████████████████████████████████████████████████████████████████████▌            | 52000/60000 [4:33:22<42:05,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 52000; Percent complete: 86.7%; Average loss: 4.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████████████████▏          | 53000/60000 [4:38:27<35:38,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 53000; Percent complete: 88.3%; Average loss: 4.7922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████████▋         | 54000/60000 [4:43:33<31:33,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 54000; Percent complete: 90.0%; Average loss: 4.7828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████████████████▎       | 55000/60000 [4:48:38<25:17,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 55000; Percent complete: 91.7%; Average loss: 4.7793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████▊      | 56000/60000 [4:53:45<20:29,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 56000; Percent complete: 93.3%; Average loss: 4.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████████████████▎    | 57000/60000 [4:58:50<15:29,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 57000; Percent complete: 95.0%; Average loss: 4.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████████████████████████████████████████████████████▉   | 58000/60000 [5:03:55<10:09,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 58000; Percent complete: 96.7%; Average loss: 4.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████▍ | 59000/60000 [5:09:06<04:59,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 59000; Percent complete: 98.3%; Average loss: 4.7735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████▉| 59999/60000 [5:14:17<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 60000; Percent complete: 100.0%; Average loss: 4.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 60000/60000 [5:15:48<00:00,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initializations\n",
    "print('Initializing ...')\n",
    "start_iteration = 1\n",
    "print_loss = 0\n",
    "\n",
    "# Training loop\n",
    "print(\"Training...\")\n",
    "for iteration in tqdm(range(start_iteration, n_iteration + 1)):\n",
    "    training_batch = training_batches[iteration - 1]\n",
    "    # Extract fields from batch\n",
    "    input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "    # Run a training iteration with batch\n",
    "    loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "    print_loss += loss\n",
    "\n",
    "    # Print progress\n",
    "    if iteration % print_every == 0:\n",
    "        print_loss_avg = print_loss / print_every\n",
    "        print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "        print_loss = 0\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (iteration % save_every == 0):\n",
    "        directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        torch.save({\n",
    "            'iteration': iteration,\n",
    "            'en': encoder.state_dict(),\n",
    "            'de': decoder.state_dict(),\n",
    "            'en_opt': encoder_optimizer.state_dict(),\n",
    "            'de_opt': decoder_optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'voc_dict': voc.__dict__,\n",
    "            'embedding': embedding.state_dict()\n",
    "        }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, k):\n",
    "        super(BeamSearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.k = k\n",
    "    \n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * Voc.SOS_TOKEN_INDEX\n",
    "        candidates = [{\n",
    "            'Hidden': decoder_hidden,\n",
    "            'Inputs': decoder_input,\n",
    "            'Tokens': [], \n",
    "            'Scores': []\n",
    "        }]\n",
    "\n",
    "\n",
    "        dones = []\n",
    "        for _ in range(max_length):\n",
    "            next_candidates = []\n",
    "            for candidate in candidates:\n",
    "                current_input = candidate['Inputs']\n",
    "                if current_input == Voc.EOS_TOKEN_INDEX:\n",
    "                    dones.append(candidate)\n",
    "                    continue\n",
    "                current_hidden = candidate['Hidden']\n",
    "                decoder_output, decoder_hidden = self.decoder(current_input, current_hidden, encoder_outputs)\n",
    "                c_scores, c_input = torch.topk(decoder_output, self.k, dim=1)\n",
    "                for s, i in zip(c_scores[0], c_input[0]):\n",
    "                    new_score = candidate['Scores'] + [s]\n",
    "                    new_tokens = candidate['Tokens'] + [i]\n",
    "                    \n",
    "                    next_candidates.append({\n",
    "                        'Hidden': decoder_hidden,\n",
    "                        'Inputs': i.unsqueeze(0).unsqueeze(0),\n",
    "                        'Tokens': new_tokens, \n",
    "                        'Scores': new_score\n",
    "                    })\n",
    "\n",
    "            next_candidates.sort(key=lambda e: sum(e['Scores'])/(len(e['Scores']))*len(set(e['Tokens']))*len(set(e['Tokens']))/len(e['Tokens'])/len(e['Tokens']), reverse=True)\n",
    "            if self.k <= len(dones):\n",
    "                break\n",
    "            candidates = next_candidates[:self.k-len(dones)]\n",
    "        \n",
    "        for candidate in candidates:\n",
    "            current_input = candidate['Inputs']\n",
    "            if current_input == Voc.EOS_TOKEN_INDEX:\n",
    "                dones.append(candidate)\n",
    "\n",
    "        candidates = dones\n",
    "        candidates.sort(key=lambda e: sum(e['Scores'])/(len(e['Scores']))*len(set(e['Tokens']))*len(set(e['Tokens']))/len(e['Tokens'])/len(e['Tokens']), reverse=True)  \n",
    "        \n",
    "        \"\"\"\n",
    "        print(len(candidates))\n",
    "        for c in candidates:\n",
    "            r = torch.stack(c['Tokens'])\n",
    "            s = torch.stack(c['Scores'])\n",
    "            print(r)\n",
    "            print(s)\n",
    "            decoded_words = [voc.index2word[token.item()] for token in r]\n",
    "            print(decoded_words, sum(s).item())\n",
    "            #print(sum(s))\n",
    "        print(candidates[0]['Tokens'])\n",
    "        \"\"\"\n",
    "        if candidates:\n",
    "            candidate = random.choice(candidates)\n",
    "            r = torch.stack(candidate['Tokens'])\n",
    "            s = torch.stack(candidate['Scores'])\n",
    "\n",
    "            return r, s\n",
    "    \n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * Voc.SOS_TOKEN_INDEX\n",
    "        print(decoder_input)\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            print(decoder_output)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            print(decoder_input)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "            print(decoder_input)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=10):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [words_to_indexes(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    #lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    #inputs = ['今天天气不错', 'q']\n",
    "    input_sentence = ''\n",
    "    i = 0\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            #input_sentence = inputs[i]\n",
    "            i += 1\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            #input_sentence = normalizeString(input_sentence)\n",
    "            input_sentence = [x for x in jieba.cut(input_sentence)]\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\save\\s2s_model\\LCCC-base\\2-2_500\\60000_checkpoint.tar\n"
     ]
    }
   ],
   "source": [
    "checkpoint_iter = 60000\n",
    "loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "print(loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_sd = checkpoint['en']\n",
    "decoder_sd = checkpoint['de']\n",
    "encoder_optimizer_sd = checkpoint['en_opt']\n",
    "decoder_optimizer_sd = checkpoint['de_opt']\n",
    "embedding_sd = checkpoint['embedding']\n",
    "voc.__dict__ = checkpoint['voc_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(voc.num_words, hidden_size)\n",
    "embedding.load_state_dict(embedding_sd)\n",
    "\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "decoder.load_state_dict(decoder_sd)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 晚上好\n",
      "Bot: 晚上 好\n",
      "> 在干嘛呢\n",
      "Bot: 躺 尸\n",
      "> 来，一起玩\n",
      "Bot: 嗯 嗯 ， 好 的 ， 我 去\n",
      "> 我等你呀\n",
      "Bot: 等 我 等 你\n",
      "> 我等你，快来\n",
      "Bot: 等 我 等 你\n",
      "> 傻\n",
      "Bot: 傻 傻 傻\n",
      "> 真傻\n",
      "Bot: 好 吧 ！\n"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "#searcher = GreedySearchDecoder(encoder, decoder)\n",
    "searcher = BeamSearchDecoder(encoder, decoder, 10)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '喜欢', '你']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wds = [x for x in jieba.cut('我喜欢你')]\n",
    "wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1] + [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n3090",
   "language": "python",
   "name": "n3090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
